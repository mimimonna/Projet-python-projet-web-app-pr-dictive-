{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet Python : Projet App Prédictive "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notre problèmatique choisi est : Comment prédire le revenu d'un film grâce à ses données ? Peut-on estimer le succès financier d'un film à partir de ses caratèristiques ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importation des bibliothèques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette prèmiere étape, nous allons importer les bibliothèques nécessaires pour manipuler les données, entraîner notre \n",
    "modèle de machine learning et sauvegarder ce modèle pour l'utiliser plus tard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split #machine learning\n",
    "from sklearn.ensemble import RandomForestRegressor #machine learning\n",
    "import joblib as jbl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Chargement et préparation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous chargeons notre dataset puis nous supprimons les lignes contenant des valeurs manquantes ou unitiles pour notre projet ainsi éviter les erreurs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Charger le dataset\n",
    "df = pd.read_csv(\"movies_success_predict.csv\")\n",
    "\n",
    "#Nettoyage des données\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Sélectionner les variables importantes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous choissions les colonnes qui peuvent potentillement influencer le revenu d'un film. Cela inclut : le genre, le réalisateur, les acteurs, la durée, l'année de sortie, la note IMDb et le metascore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Liste des colonnes explicatives qui sont pertinentes pour la prédiction\n",
    "features = [\n",
    "    \"Genre\", \"Director\", \"Actors\",\n",
    "    \"Year\", \"Runtime (Minutes)\",\n",
    "    \"Rating\", \"Metascore\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Encodage des variables catégorielles et séparation des données : Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Certaines colonnes de notre dataset sont du texte donc pour cela nous devons transformer les données en chiffre avec la méthode du \"one-hot encoding\". Mais pour cela on doit définir X et y . \n",
    "\n",
    "Donc y= La colonne \"Revenue(Millions) et X = Contient toutes les autres colonnes.\n",
    "\n",
    "On va transformer le texte en colonnes de 0 à 1 pour le modèle puisse comprendre les données du dataset avec la méthode \"dummies\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Définir X et y\n",
    "X = df[features]\n",
    "y = df[\"Revenue (Millions)\"]\n",
    "\n",
    "#Encodage des catégories en one-hot\n",
    "X_encoded = pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous divisions notre dataset en deu xparties :\n",
    "- pour entraîner le modèle ('train)\n",
    "- pour tester le modèle ('test')\n",
    "\n",
    "Cela va nous permettre de savoir si le modèle qu'on utilise est performant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train #test \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Entraînement du modèle\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Sauvegarder le modèle avec Joblit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois le modèle entraîner, nous le sauvegardons dans un fichier .pkl avec les colonnes qu'on va utiliser pour la prédiction. Cela va nous permettre de le réutiliser dans notre application Streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sauvegarde du modèle et des colonnes utilisées\n",
    "jbl.dump(model, \"movies_success_predict.pkl\")\n",
    "jbl.dump(X_encoded.columns.tolist(), \"new_columns.pkl\")\n",
    "\n",
    "print(\"Modèle entraîné et sauvegardé pour la prédiction du revenu.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
